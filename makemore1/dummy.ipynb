{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '<S>',\n",
       " '<E>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "list(string.ascii_lowercase) + [\"<S>\", \"<E>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.1-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl.metadata (165 kB)\n",
      "     ---------------------------------------- 0.0/165.9 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 30.7/165.9 kB 445.2 kB/s eta 0:00:01\n",
      "     ------ ------------------------------ 30.7/165.9 kB 445.2 kB/s eta 0:00:01\n",
      "     ---------------------------- --------- 122.9/165.9 kB 1.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 153.6/165.9 kB 1.1 MB/s eta 0:00:01\n",
      "     -----------------------------------  163.8/165.9 kB 756.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 165.9/165.9 kB 714.1 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\miniconda3\\envs\\numpygradenv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\miniconda3\\envs\\numpygradenv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\miniconda3\\envs\\numpygradenv\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\miniconda3\\envs\\numpygradenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.1-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/8.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/8.0 MB 8.5 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.6/8.0 MB 5.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/8.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/8.0 MB 5.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.4/8.0 MB 5.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.4/8.0 MB 5.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.0 MB 4.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.0 MB 4.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.7/8.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.2/8.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.9/8.0 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.2/8.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.6/8.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.0/8.0 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.5/8.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.0/8.0 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.2/8.0 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/8.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 6.4 MB/s eta 0:00:00\n",
      "Using cached contourpy-1.2.1-cp312-cp312-win_amd64.whl (189 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.7/2.2 MB 44.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.2 MB 20.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 12.7 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.0/2.6 MB 31.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.6/2.6 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.6 MB 20.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 14.8 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.9.1 pillow-10.4.0 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\miniconda3\\envs\\numpygradenv\\Lib\\site-packages\\torch\\__init__.py:655\u001b[0m, in \u001b[0;36mget_default_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m device\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;66;03m# TODO: Call like get_device_index() method corresponding to\u001b[39;00m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;66;03m# each device type\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\miniconda3\\envs\\numpygradenv\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\miniconda3\\envs\\numpygradenv\\Lib\\site-packages\\torch\\cuda\\__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpygradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
